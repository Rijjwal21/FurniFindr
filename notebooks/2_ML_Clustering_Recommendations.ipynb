{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd326f3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "DATA_PATH = \"../backend/app/data_ingestion/sample_data.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Clean categories\n",
    "def safe_literal_eval(val):\n",
    "    if not isinstance(val, str) or not val.startswith('['):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "df['categories_clean'] = df['categories'].apply(safe_literal_eval)\n",
    "\n",
    "# --- Create a combined text 'corpus' for NLP tasks ---\n",
    "df['corpus'] = df['title'] + \" \" + \\\n",
    "               df['description'] + \" \" + \\\n",
    "               df['brand'] + \" \" + \\\n",
    "               df['material'] + \" \" + \\\n",
    "               df['color'] + \" \" + \\\n",
    "               df['categories_clean'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "print(f\"Data loaded. Total items: {len(df)}\")\n",
    "print(\"\\nExample corpus:\")\n",
    "print(df['corpus'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397de210",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# 2. Fit and transform the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['corpus'])\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(\"This matrix represents each product as a vector of keyword scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53323873",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Compute the Cosine Similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "print(f\"Cosine similarity matrix shape: {cosine_sim_matrix.shape}\")\n",
    "print(\"This matrix shows the similarity between every pair of products (0 to 1).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eb762",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Create a function to get recommendations\n",
    "indices = pd.Series(df.index, index=df['uniq_id']).drop_duplicates()\n",
    "\n",
    "def get_tfidf_recommendations(uniq_id, top_k=3):\n",
    "    \"\"\"Gets top_k recommendations for a given uniq_id.\"\"\"\n",
    "    if uniq_id not in indices:\n",
    "        return f\"Error: uniq_id {uniq_id} not found.\"\n",
    "    \n",
    "    # Get the index of the product\n",
    "    idx = indices[uniq_id]\n",
    "    \n",
    "    # Get the pairwise similarity scores for this product\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "    \n",
    "    # Sort the products based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the scores of the top_k most similar products (skip index 1, it's the item itself)\n",
    "    top_product_indices = [i[0] for i in sim_scores[1:top_k+1]]\n",
    "    top_product_scores = [i[1] for i in sim_scores[1:top_k+1]]\n",
    "    \n",
    "    # Return the titles and scores\n",
    "    return df[['title', 'uniq_id']].iloc[top_product_indices].assign(similarity_score=top_product_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee547df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Item 1: The 'Modern Velvet Accent Chair'\n",
    "test_id_1 = 'a1b2c3d4-0001'\n",
    "print(f\"--- Recommendations for: {df[df['uniq_id'] == test_id_1]['title'].values[0]} ---\")\n",
    "print(get_tfidf_recommendations(test_id_1, top_k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32421cf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Item 2: The 'L-Shaped Computer Desk'\n",
    "test_id_2 = 'a1b2c3d4-0005'\n",
    "print(f\"--- Recommendations for: {df[df['uniq_id'] == test_id_2]['title'].values[0]} ---\")\n",
    "print(get_tfidf_recommendations(test_id_2, top_k=3))\n",
    "print(\"\\nEvaluation: This model recommends items based on shared keywords.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894e4b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load the embedding model (this is the same one used in the API)\n",
    "print(\"Loading embedding model... This might take a moment.\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b491f6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Generate embeddings for all product corpuses\n",
    "print(\"Generating embeddings for all products...\")\n",
    "corpus_embeddings = embedding_model.encode(df['corpus'].tolist(), show_progress_bar=True)\n",
    "print(f\"Embeddings generated. Shape: {corpus_embeddings.shape}\")\n",
    "print(\"These are semantic vectors that understand meaning, not just keywords.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd33cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Run K-Means Clustering\n",
    "# For this small dataset, we'll pick k=3 (e.g., 'Chairs', 'Tables/Desks', 'Storage')\n",
    "num_clusters = 3\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "kmeans.fit(corpus_embeddings)\n",
    "\n",
    "# Assign cluster labels back to the DataFrame\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "print(\"Clustering complete. Cluster labels added to DataFrame.\")\n",
    "df[['title', 'cluster']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffd1da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce dimensions to 2D for plotting\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca.fit_transform(corpus_embeddings)\n",
    "\n",
    "df['pca_x'] = embeddings_2d[:, 0]\n",
    "df['pca_y'] = embeddings_2d[:, 1]\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x='pca_x',\n",
    "    y='pca_y',\n",
    "    hue='cluster',\n",
    "    palette=sns.color_palette(\"hsv\", n_colors=num_clusters),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")\n",
    "plt.title('Product Clusters (PCA Visualization)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n",
    "\n",
    "print(\"Evaluation: This plot shows how K-Means has grouped semantically similar items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39fa632",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Print the titles of items in each cluster to see what was grouped\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\n--- Cluster {i} ---\")\n",
    "    cluster_items = df[df['cluster'] == i]['title']\n",
    "    print(cluster_items.to_markdown(index=False))\n",
    "    \n",
    "print(\"\\nEvaluation: The clusters successfully group items by their semantic meaning (e.g., chairs, tables, storage).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359e093",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
